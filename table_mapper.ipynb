{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf3c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import duckdb\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import BallTree\n",
    "import vptree\n",
    "import nmslib\n",
    "import threading\n",
    "import bktree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520e75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b238fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment:\n",
    "    redset_scansets = redset_scansets = [(i, i+1) for i in range(1, 10)]\n",
    "else:\n",
    "    redset_scansets = get_redset_scansets()\n",
    "num_redset_tables = max([max(scanset) for scanset in redset_scansets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9678b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcds_scansets = get_tpcds_scansets()\n",
    "num_tpcds_tables = max([max(scanset) for scanset in tpcds_scansets if scanset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9313deed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_redset_tables, num_tpcds_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79492158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4871cda",
   "metadata": {},
   "source": [
    "## Python + Index in C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d206570",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 64\n",
    "N_ITERATIONS_PER_THREAD = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70adca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.608015060424805,\n",
       " 9,\n",
       " {1: 17, 2: 14, 3: 17, 4: 14, 5: 18, 6: 16, 7: 8, 8: 18, 9: 8, 10: 12})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bktree\n",
    "\n",
    "ITERATIONS = 10\n",
    "\n",
    "redset_scanset_counters = Counter(redset_scansets)\n",
    "\n",
    "assert type(redset_scansets) == list, \"redset_scansets should be a list of scansets\"\n",
    "assert type(tpcds_scansets) == list, \"tpcds_scansets should be a list of scansets\"\n",
    "\n",
    "def get_random_assignment(n, k, seed=None):\n",
    "    assignment = dict()\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    for i in range(1, n + 1):\n",
    "        assignment[i] = random.randint(1, k)\n",
    "    return assignment\n",
    "\n",
    "def get_distance(scanset1, scanset2):\n",
    "    a = Counter(scanset1) if isinstance(scanset1, list) or isinstance(scanset1, tuple) else scanset1\n",
    "    b = Counter(scanset2) if isinstance(scanset2, list) or isinstance(scanset2, tuple) else scanset2\n",
    "    a.subtract(b)\n",
    "    return sum(abs(v) for v in a.values())\n",
    "\n",
    "def convert_scanset_for_distance(scanset, assignment):\n",
    "    if True:\n",
    "        ts = Counter(scanset)\n",
    "        collisions = dict() # TPCDS table -> set of redset tables in our scanset\n",
    "        problematic_r_tables = set()\n",
    "        for r_table in scanset:\n",
    "            b_table = assignment[r_table]\n",
    "            if b_table not in collisions:\n",
    "                collisions[b_table] = set()\n",
    "            collisions[b_table].add(r_table)\n",
    "            problematic_r_tables.add(r_table)\n",
    "        chosen_r_tables = set()\n",
    "        for _, r_tables in collisions.items():\n",
    "            if len(r_tables) == 1:\n",
    "                chosen_r_tables.add(r_tables.pop())\n",
    "            else:\n",
    "                # If there are multiple Redset tables, we choose the one that is most common in the scanset\n",
    "                best_num_occs = 0\n",
    "                best_r_table = None\n",
    "                for r_table in r_tables:\n",
    "                    if ts[r_table] > best_num_occs:\n",
    "                        best_num_occs = ts[r_table]\n",
    "                        best_r_table = r_table\n",
    "                chosen_r_tables.add(best_r_table)\n",
    "        return [\n",
    "            assignment[table] if table not in problematic_r_tables or table in chosen_r_tables else -1\n",
    "            for table in scanset\n",
    "        ]\n",
    "    else:\n",
    "        return [assignment[table] for table in scanset]\n",
    "\n",
    "bk_tree = bktree.BKTree(tpcds_scansets)\n",
    "\n",
    "r_table_to_scansets = defaultdict(list)\n",
    "for idx, scanset in enumerate(redset_scansets):\n",
    "    for r_table in scanset:\n",
    "        r_table_to_scansets[r_table].append(idx)\n",
    "\n",
    "def get_assignment_distance(assignment, affected_r_scansets, bk_tree, per_rs_distance, compute_per_rs_distance, update_per_rs_distance=False):\n",
    "    total_distance = 0\n",
    "    delta = 0\n",
    "    for r_scanset_idx in affected_r_scansets:\n",
    "        r_scanset = redset_scansets[r_scanset_idx]\n",
    "        occs = redset_scanset_counters[r_scanset] # TODO: Make sure the traversal order of the keys in the dict is constant\n",
    "\n",
    "        new_distance = bk_tree.nearest(convert_scanset_for_distance(r_scanset, assignment))[1] * occs\n",
    "        if compute_per_rs_distance:\n",
    "            total_distance += new_distance\n",
    "            per_rs_distance.append(new_distance)\n",
    "        else:\n",
    "            old_distance = per_rs_distance[r_scanset_idx]\n",
    "            delta += new_distance - old_distance\n",
    "            if update_per_rs_distance:\n",
    "                per_rs_distance[r_scanset_idx] = new_distance\n",
    "    return total_distance if compute_per_rs_distance else delta\n",
    "\n",
    "start_time = time.time()\n",
    "def thread_work(n_iterations, thread_idx):\n",
    "    best_distance = float('inf')\n",
    "    total_time_dist = 0\n",
    "    for itr in range(n_iterations):\n",
    "        assignment = get_random_assignment(num_redset_tables, num_tpcds_tables, seed=thread_idx*1000+itr) # When multi-threaded, make sure that determinism is not broken\n",
    "        current_per_rs_distance = []\n",
    "        current_distance = get_assignment_distance(assignment, [i for i in range(len(redset_scansets))], bk_tree, current_per_rs_distance, True)\n",
    "        while True:\n",
    "            best_new_distance = float('inf')\n",
    "            best_new_assignment = None\n",
    "            for rt in range(1, num_redset_tables + 1): # What if we reassign this table?\n",
    "                old_assignment = assignment[rt]\n",
    "                for bt in range(1, num_tpcds_tables + 1): # Iterate over all possible assignments\n",
    "                    if bt == old_assignment: # This is the current assignment\n",
    "                        continue\n",
    "                    assignment[rt] = bt\n",
    "                    start_dist = time.time()\n",
    "                    new_distance = current_distance + get_assignment_distance(assignment, r_table_to_scansets[rt], bk_tree, current_per_rs_distance, False)\n",
    "                    total_time_dist += time.time() - start_dist\n",
    "                    if new_distance < best_new_distance:\n",
    "                        best_new_distance = new_distance\n",
    "                        best_new_assignment = rt, bt\n",
    "                assignment[rt] = old_assignment # Revert the assignment\n",
    "            if best_new_distance >= current_distance:\n",
    "                break # No more improvement possible. This is a (local) optimum.\n",
    "            assignment[best_new_assignment[0]] = best_new_assignment[1] # Set the best new global assignment\n",
    "            get_assignment_distance(assignment, [i for i in range(len(redset_scansets))], bk_tree, current_per_rs_distance, False, True) # Update the current distance\n",
    "            current_distance = best_new_distance\n",
    "        if current_distance < best_distance:\n",
    "            best_distance = current_distance\n",
    "            best_assignment = copy.deepcopy(assignment)\n",
    "    return best_distance, best_assignment\n",
    "\n",
    "def multi_processed():\n",
    "    from multiprocessing import Pool\n",
    "\n",
    "    worker_args = [(N_ITERATIONS_PER_THREAD, itr) for itr in range(N_THREADS)]\n",
    "\n",
    "    with Pool(processes=N_THREADS) as pool:\n",
    "        results = pool.starmap(thread_work, worker_args)\n",
    "\n",
    "    return min(results, key=lambda r: r[0])\n",
    "\n",
    "best_distance, best_assignment = multi_processed()\n",
    "\n",
    "time.time() - start_time, best_distance, best_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d75525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfeaecce",
   "metadata": {},
   "source": [
    "## Pure C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203e6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_table_to_scansets = defaultdict(list)\n",
    "for idx, scanset in enumerate(redset_scansets):\n",
    "    for r_table in scanset:\n",
    "        r_table_to_scansets[r_table].append(idx)\n",
    "\n",
    "c_r_table_to_scansets = [None] * (num_redset_tables + 1)\n",
    "for r_table, scansets in r_table_to_scansets.items():\n",
    "    c_r_table_to_scansets[r_table] = scansets\n",
    "c_r_table_to_scansets[0] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3fd32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.0, {10: 8, 9: 4, 8: 12, 7: 8, 6: 4, 5: 8, 4: 18, 3: 16, 2: 18, 1: 8})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9729795455932617"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(bktree.find_optimal_bijection(\n",
    "    N_THREADS,\n",
    "    N_ITERATIONS_PER_THREAD,\n",
    "    [1 for _ in range(len(redset_scansets))],\n",
    "    redset_scansets,\n",
    "    tpcds_scansets,\n",
    "    c_r_table_to_scansets,\n",
    "    num_redset_tables,\n",
    "    num_tpcds_tables\n",
    "))\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06309623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
